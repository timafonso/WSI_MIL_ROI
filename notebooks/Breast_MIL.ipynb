{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(os.path.abspath('../KimiaNet'))\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# ============================== Torch Imports =====================================\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# =================================== Metrics =======================================\n",
    "\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryRecall, BinaryF1Score\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ============================= Models and Datasets =================================\n",
    "\n",
    "from model import Attention, GatedAttention, AdditiveAttention\n",
    "from WSI_dataloader import collate, BreastWSIDataset, BreastEmbeddingDataset\n",
    "\n",
    "# ========================= TensorBoard and Logging =================================\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================ PARAMETERS ====================================================\n",
    "CUDA = True\n",
    "SEED = 5\n",
    "\n",
    "# --------------------------------- Hyperparameters ----------------------------------------\n",
    "\n",
    "LR = 0.0001\n",
    "REG = 10e-5\n",
    "NUM_EPOCHS = 40\n",
    "KFOLD_SPLITS = 5\n",
    "BAGS_PER_BATCH = 3\n",
    "\n",
    "# --------------------------------- Metrics Indexes -----------------------------------------\n",
    "\n",
    "LOSS_INDEX = 0\n",
    "ACCURACY_INDEX = 1\n",
    "AUC_INDEX = 2\n",
    "RECALL_INDEX = 3\n",
    "F1_INDEX = 4\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "EMBEDDINGS = True\n",
    "USE_TENSORBOARD = True\n",
    "\n",
    "DATASET_HDF5 = \"/media/mdastorage/breast_5x_aug_2.h5\"\n",
    "DATASET_FOLDER = \"/media/mdastorage/breast_5x_2\"\n",
    "CUDA_DEVICE = \"cuda:0\"\n",
    "TENSORBOARD_DIRECTORY = \"../runs/cross-val/Breast5x_Aug2_AdditiveAttention\"\n",
    "\n",
    "MODEL_WEIGHTS_FILE = \"../model_weights/additiveAttentionMIL_aug2.pt\"\n",
    "TEST_SET_INDICES = 'test_indices.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is ON!\n"
     ]
    }
   ],
   "source": [
    "# =============================================== Initializations ===============================================\n",
    "\n",
    "torch.cuda.init()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "cuda = CUDA and torch.cuda.is_available()\n",
    "device = torch.device(CUDA_DEVICE)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    print('\\nGPU is ON!')\n",
    "\n",
    "splits = KFold(n_splits = KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "#splits = StratifiedKFold(n_splits = KFOLD_SPLITS, shuffle=False, random_state=None)\n",
    "\n",
    "AttentionModel = Attention()\n",
    "GatedAttentionModel = GatedAttention()\n",
    "if cuda:\n",
    "    AttentionModel.cuda()\n",
    "    GatedAttentionModel.cuda()\n",
    "    AttentionModel.to(device)\n",
    "    GatedAttentionModel.to(device)\n",
    "\n",
    "optimizer = optim.Adam(AttentionModel.parameters(), lr=LR, betas=(0.9, 0.999), weight_decay=REG)\n",
    "if USE_TENSORBOARD:\n",
    "    writer = SummaryWriter(TENSORBOARD_DIRECTORY)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786 786 786\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Dataset Fetched!\n"
     ]
    }
   ],
   "source": [
    "# =========================================== Dataset ======================================================\n",
    "\n",
    "if EMBEDDINGS:\n",
    "    dataset = BreastEmbeddingDataset(DATASET_HDF5)\n",
    "else:\n",
    "    dataset = BreastWSIDataset(DATASET_FOLDER, 5, (0,370), (0,370), data_augmentations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================== Metrics ======================================================\n",
    "\n",
    "auc_metric = BinaryAUROC().to(device)    \n",
    "accuracy_metric = BinaryAccuracy(threshold=0.5).to(device)\n",
    "recall_metric = BinaryRecall(threshold=0.5).to(device)\n",
    "F1_metric = BinaryF1Score(threshold=0.5).to(device)\n",
    "\n",
    "def calculate_auc(probs, true_labels):\n",
    "    auc_metric.update(probs, true_labels)\n",
    "    auc = auc_metric.compute()\n",
    "    auc_metric.reset()\n",
    "    return auc\n",
    "\n",
    "def calculate_accuracy(probs, true_labels):\n",
    "    return accuracy_metric(probs, true_labels)\n",
    "\n",
    "def calculate_recall(probs, true_labels):\n",
    "    return recall_metric(probs, true_labels)\n",
    "\n",
    "def calculate_F1(probs, true_labels):\n",
    "    return F1_metric(probs, true_labels)\n",
    "\n",
    "\n",
    "def calculate_metrics(probs, true_labels):\n",
    "    probs = torch.FloatTensor(probs).to(device)\n",
    "    true_labels = torch.FloatTensor(true_labels).to(device)\n",
    "    \n",
    "    accuracy = calculate_accuracy(probs, true_labels)\n",
    "    auc = calculate_auc(probs, true_labels)\n",
    "    f1 = calculate_F1(probs, true_labels)\n",
    "    recall = calculate_recall(probs, true_labels)\n",
    "    \n",
    "    return accuracy, auc, f1, recall\n",
    "\n",
    "def get_classification_report(probs, true_labels):\n",
    "    report = classification_report(true_labels, probs, target_names=[\"Negative\", \"Positive\"])\n",
    "    print(report)\n",
    "\n",
    "def metrics_to_tensorboard(fold_metrics):\n",
    "    if USE_TENSORBOARD:\n",
    "        for fold in range(fold_metrics.shape[0]):\n",
    "            for epoch in range(fold_metrics.shape[1]):\n",
    "                writer.add_scalar('{} Loss - Fold {}'.format(\"training\", fold), fold_metrics[fold, epoch, 0, LOSS_INDEX], epoch)\n",
    "                writer.add_scalar('{} Accuracy - Fold {}'.format(\"training\", fold), fold_metrics[fold, epoch, 0, ACCURACY_INDEX], epoch)\n",
    "                writer.add_scalar('{} AUC - Fold {}'.format(\"training\", fold), fold_metrics[fold, epoch, 0, AUC_INDEX], epoch)\n",
    "                writer.add_scalar('{} Recall - Fold {}'.format(\"training\", fold), fold_metrics[fold, epoch, 0, RECALL_INDEX], epoch)\n",
    "                writer.add_scalar('{} F1 - Fold {}'.format(\"training\", fold), fold_metrics[fold, epoch, 0, F1_INDEX], epoch)\n",
    "                \n",
    "                \n",
    "                writer.add_scalar('{} Loss - Fold {}'.format(\"validation\", fold), fold_metrics[fold, epoch, 1, LOSS_INDEX], epoch)\n",
    "                writer.add_scalar('{} Accuracy - Fold {}'.format(\"validation\", fold), fold_metrics[fold, epoch, 1, ACCURACY_INDEX], epoch)\n",
    "                writer.add_scalar('{} AUC - Fold {}'.format(\"validation\", fold), fold_metrics[fold, epoch, 1, AUC_INDEX], epoch)\n",
    "                writer.add_scalar('{} Recall - Fold {}'.format(\"validation\", fold), fold_metrics[fold, epoch, 0, RECALL_INDEX], epoch)\n",
    "                writer.add_scalar('{} F1 - Fold {}'.format(\"validation\", fold), fold_metrics[fold, epoch, 0, F1_INDEX], epoch)\n",
    "\n",
    "        for epoch in range(fold_metrics.shape[1]):\n",
    "            writer.add_scalar('{} Loss - Fold {}'.format(\"training\", \"avg\"), np.mean(fold_metrics[:, epoch, 0, LOSS_INDEX], axis=0), epoch)\n",
    "            writer.add_scalar('{} Accuracy - Fold {}'.format(\"training\", \"avg\"), np.mean(fold_metrics[:, epoch, 0, ACCURACY_INDEX], axis=0), epoch)\n",
    "            writer.add_scalar('{} AUC - Fold {}'.format(\"training\", \"avg\"), np.mean(fold_metrics[:, epoch, 0, AUC_INDEX], axis=0), epoch)\n",
    "            writer.add_scalar('{} Recall - Fold {}'.format(\"training\", \"avg\"), np.mean(fold_metrics[fold, epoch, 0, RECALL_INDEX]), epoch)\n",
    "            writer.add_scalar('{} F1 - Fold {}'.format(\"training\", \"avg\"), np.mean(fold_metrics[fold, epoch, 0, F1_INDEX]), epoch)   \n",
    "\n",
    "            \n",
    "            writer.add_scalar('{} Loss - Fold {}'.format(\"validation\", \"avg\"), np.mean(fold_metrics[:, epoch, 1, LOSS_INDEX], axis=0), epoch)\n",
    "            writer.add_scalar('{} Accuracy - Fold {}'.format(\"validation\", \"avg\"), np.mean(fold_metrics[:, epoch, 1, ACCURACY_INDEX], axis=0), epoch)\n",
    "            writer.add_scalar('{} AUC - Fold {}'.format(\"validation\", \"avg\"), np.mean(fold_metrics[:, epoch, 1, AUC_INDEX], axis=0), epoch)\n",
    "            writer.add_scalar('{} Recall - Fold {}'.format(\"validation\", \"avg\"), np.mean(fold_metrics[fold, epoch, 0, RECALL_INDEX]), epoch)\n",
    "            writer.add_scalar('{} F1 - Fold {}'.format(\"validation\", \"avg\"), np.mean(fold_metrics[fold, epoch, 0, F1_INDEX]), epoch)         \n",
    "\n",
    "# ======================================= Auxiliary Functions =============================================\n",
    "\n",
    "def count_labels(label, pos, neg):\n",
    "    if label == 0:\n",
    "        neg += 1\n",
    "    else:\n",
    "        pos += 1\n",
    "    return pos, neg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================== Train Functions =============================================\n",
    "\n",
    "def train_epoch_embeddings(model, dataloader, optimizer, epoch, fold=\"\"):\n",
    "    model.train()\n",
    "    train_loss, train_error = 0., 0.\n",
    "    train_correct = 0\n",
    "    pos, neg = 0, 0\n",
    "    probs, true_labels = [], []\n",
    "    nan_loss = False\n",
    "    num_aug = 0\n",
    "    num_nan = 0\n",
    "\n",
    "    for batch_idx, (data, coords, label, path) in enumerate(dataloader):\n",
    "        bag_label = label[0]\n",
    "        pos, neg = count_labels(label, pos, neg)\n",
    "        num_aug = data.shape[0]\n",
    "        for aug in range(num_aug):\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "            \n",
    "            embedding = data[aug,:,:]\n",
    "            \n",
    "            \n",
    "            if cuda:\n",
    "                embedding, bag_label = embedding.to(device), label.to(device)\n",
    "            \n",
    "            loss, _ = model.calculate_objective(embedding, bag_label)\n",
    "\n",
    "\n",
    "            if torch.isnan(embedding).any():\n",
    "                num_nan += 1\n",
    "                continue\n",
    "            \n",
    "\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            error, Y_hat, Y_prob = model.calculate_classification_error(embedding, bag_label)\n",
    "            if torch.any(torch.isnan(Y_prob)):\n",
    "                #print(\"y is nan\", embedding)\n",
    "                num_nan += 1\n",
    "                continue\n",
    "\n",
    "            train_error += error\n",
    "            train_correct += (Y_hat == bag_label).sum().item()\n",
    "\n",
    "            probs.append(Y_prob.item())\n",
    "            true_labels.append(label[0].item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return train_loss, train_correct, probs, true_labels, num_nan\n",
    "\n",
    "\n",
    "# ========================================== Validation Functions =====================================================\n",
    "\n",
    "def valid_epoch_embeddings(model, dataloader, epoch, fold=\"\", get_scores=False):\n",
    "    model.eval()\n",
    "    valid_loss, valid_error, valid_correct = 0., 0., 0\n",
    "    probs, true_labels = [], []\n",
    "    pos, neg = 0, 0\n",
    "    nan_loss = False\n",
    "    num_aug = 0\n",
    "    attention_scores = {}\n",
    "\n",
    "    for batch_idx, (data, coords, label, path) in enumerate(dataloader):\n",
    "        bag_label = label[0]\n",
    "        pos, neg = count_labels(bag_label, pos, neg)\n",
    "        num_aug = data.shape[0]\n",
    "        embedding = data[0,:,:]\n",
    "        if cuda:\n",
    "            embedding, bag_label = embedding.to(device), label.to(device)\n",
    "\n",
    "        loss, attention_weights = model.calculate_objective(embedding, bag_label)\n",
    "        error, Y_hat, Y_prob = model.calculate_classification_error(embedding, bag_label)\n",
    "\n",
    "        if torch.any(torch.isnan(Y_prob)):\n",
    "            #print(\"y is nan\", embedding)\n",
    "            num_nan += 1\n",
    "            continue\n",
    "\n",
    "        if get_scores:\n",
    "            attention_scores[path[0]] = (coords, attention_weights)\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "        valid_error += error\n",
    "        valid_correct += (Y_hat == bag_label).sum().item()\n",
    "        probs.append(Y_prob.item())\n",
    "        true_labels.append(label[0].item())\n",
    "\n",
    "\n",
    "    if epoch == \"validation\" and USE_TENSORBOARD:\n",
    "        accuracy, auc, f1, recall = calculate_metrics(probs, true_labels)\n",
    "        writer.add_text('loss', \"{:.4f}\".format(valid_loss/len(dataloader)))\n",
    "        writer.add_text('auc', \"{:.4f}\".format(auc))\n",
    "        writer.add_text('accuracy',\"{:.4f}\".format(accuracy))\n",
    "        writer.add_text('f1',\"{:.4f}\".format(f1))\n",
    "        writer.add_text('recall',\"{:.4f}\".format(recall))\n",
    "\n",
    "\n",
    "    if get_scores:\n",
    "        return valid_loss, valid_correct, probs, true_labels, attention_scores\n",
    "    else:\n",
    "        return valid_loss, valid_correct, probs, true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================ Train/Test Split =====================================\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset, batch_size=1, num_workers=8, pin_memory=True, prefetch_factor=20,collate_fn=collate)\n",
    "test_loader = data_utils.DataLoader(test_dataset, batch_size=1, num_workers=8, pin_memory=True, prefetch_factor=20,collate_fn=collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "def fold_data(loader, fold, desc):\n",
    "    bag_sizes = [0]*len(loader)\n",
    "    indexes = [i for i in range(len(loader))]\n",
    "    print(len(indexes), len(bag_sizes))\n",
    "    pos,neg = 0,0\n",
    "    for batch_idx, (data, coords, label, path) in enumerate(loader):\n",
    "        bag_label = label[0]\n",
    "        pos, neg = count_labels(bag_label, pos, neg)\n",
    "        embedding = data[0,:,:]\n",
    "        bag_sizes[embedding.shape[0]] += 1\n",
    "    fig, ax = plt.subplots(1,2, figsize=(40,20))\n",
    "    ax.bar(indexes, bag_sizes)\n",
    "    plt.title(\"fold: \" + str(fold) + \" \" + desc)\n",
    "    #print(desc + \" \" + str(fold) + \" mean \" + str(statistics.mean(bag_sizes)))\n",
    "    #print(desc + \" \" + str(fold) + \" stdev \" + str(statistics.stdev(bag_sizes)))\n",
    "    #print(desc + \" \" + str(fold) + \" median \" + str(statistics.median(bag_sizes)))\n",
    "    plt.show()\n",
    "\n",
    "def check_fold_data(train_loader, test_loader, fold):\n",
    "    train_paths, test_paths = [], []\n",
    "    train_pos_neg, test_pos_neg = [0,0], [0,0]\n",
    "    for batch_idx, (data, coords, label, path) in enumerate(train_loader):\n",
    "        train_paths.append(path[0])\n",
    "        train_pos_neg[label] += 1\n",
    "    for batch_idx, (data, coords, label, path) in enumerate(test_loader):\n",
    "        test_paths.append(path[0])\n",
    "        test_pos_neg[label] += 1\n",
    "\n",
    "    train_paths = set(train_paths)\n",
    "    test_paths = set(test_paths)\n",
    "\n",
    "    if len(train_paths.intersection(test_paths)) > 0:\n",
    "        print(\"Duplicate found \", str(fold))\n",
    "\n",
    "    # print(\"train:\", train_pos_neg)\n",
    "    # print(\"test:\", test_pos_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, dataset):\n",
    "    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "    fold_metrics = np.empty((KFOLD_SPLITS, NUM_EPOCHS, 2, 5))\n",
    "\n",
    "    for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "        model = AdditiveAttention()\n",
    "        model.to(device)\n",
    "        model.apply(weights_init)\n",
    "        print('Fold {}'.format(fold + 1))\n",
    "        train_sampler = data_utils.SubsetRandomSampler(train_idx)\n",
    "        test_sampler = data_utils.SubsetRandomSampler(val_idx)\n",
    "        train_loader = data_utils.DataLoader(dataset, batch_size=1, sampler=train_sampler, num_workers=0, pin_memory=True, collate_fn=collate)\n",
    "        test_loader = data_utils.DataLoader(dataset, batch_size=1, sampler=test_sampler, num_workers=0, pin_memory=True, collate_fn=collate)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.999), weight_decay=REG)\n",
    "\n",
    "        train_auc_epochs, train_accuracy_epochs, train_loss_epochs = [], [], []\n",
    "        test_auc_epochs, test_accuracy_epochs, test_loss = [], [], []\n",
    "        \n",
    "        for epoch in range(0, NUM_EPOCHS):\n",
    "            train_loss, train_correct, train_probs, train_true_labels, num_nan = train_epoch_embeddings(model,train_loader,optimizer, epoch, fold)\n",
    "            test_loss, test_correct, test_probs, test_true_labels = valid_epoch_embeddings(model,test_loader, epoch, fold)\n",
    "            \n",
    "            train_accuracy, train_auc, train_f1, train_recall = calculate_metrics(train_probs, train_true_labels)\n",
    "            test_accuracy, test_auc, test_f1, test_recall = calculate_metrics(test_probs, test_true_labels)   \n",
    "            \n",
    "            fold_metrics[fold, epoch, 0, LOSS_INDEX] = train_loss / (len(train_loader) * BAGS_PER_BATCH - num_nan)\n",
    "            fold_metrics[fold, epoch, 0, ACCURACY_INDEX] = train_accuracy\n",
    "            fold_metrics[fold, epoch, 0, AUC_INDEX] = train_auc\n",
    "            fold_metrics[fold, epoch, 0, F1_INDEX] = train_f1\n",
    "            fold_metrics[fold, epoch, 0, RECALL_INDEX] = train_recall\n",
    "            \n",
    "\n",
    "            fold_metrics[fold, epoch, 1, LOSS_INDEX] = test_loss / len(test_loader)\n",
    "            fold_metrics[fold, epoch, 1, ACCURACY_INDEX] = test_accuracy\n",
    "            fold_metrics[fold, epoch, 1, AUC_INDEX] = test_auc\n",
    "            fold_metrics[fold, epoch, 1, F1_INDEX] = test_f1\n",
    "            fold_metrics[fold, epoch, 1, RECALL_INDEX] = test_recall\n",
    "            \n",
    "\n",
    "    metrics_to_tensorboard(fold_metrics)\n",
    "\n",
    "\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "External Validation Loss 0.2851210172816191\n"
     ]
    }
   ],
   "source": [
    "model = cross_validation(AttentionModel, train_dataset)\n",
    "\n",
    "dataloader = data_utils.DataLoader(test_dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True, collate_fn=collate)\n",
    "\n",
    "valid_loss, valid_correct, probs, true_labels, attention_scores = valid_epoch_embeddings(model, dataloader, \"validation\", get_scores=True)\n",
    "\n",
    "#writer.close()\n",
    "print(\"External Validation Loss\", valid_loss/len(dataloader))\n",
    "torch.save(model.state_dict(), MODEL_WEIGHTS_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "test_indices = test_dataset.indices\n",
    "with open('test_indices.pkl', 'wb') as f:\n",
    "    pickle.dump(test_indices, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65ed21f19add0e62cd601ab09ae40de4e05bbfa5bc74c0c632f06cef632a585a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
